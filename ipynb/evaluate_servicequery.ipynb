{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "74f630ea-b572-4262-89ef-35b31f0aed45",
   "metadata": {},
   "source": [
    "# add module path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2293817b-3b68-4e80-92d0-63d8203540ed",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-09T09:57:30.356210Z",
     "iopub.status.busy": "2023-12-09T09:57:30.355669Z",
     "iopub.status.idle": "2023-12-09T09:57:30.360258Z",
     "shell.execute_reply": "2023-12-09T09:57:30.359482Z",
     "shell.execute_reply.started": "2023-12-09T09:57:30.356178Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "module_path = '/home/x1112436/git/sent-semantic-repo'\n",
    "sys.path.append(module_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b4661f7-ccb3-4972-8ffc-33fe6d775c94",
   "metadata": {},
   "source": [
    "# Read real data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9c773a7c-ebfc-4573-9f5a-b4f1f22563df",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-28T05:22:18.073026Z",
     "iopub.status.busy": "2023-11-28T05:22:18.072187Z",
     "iopub.status.idle": "2023-11-28T05:22:18.078762Z",
     "shell.execute_reply": "2023-11-28T05:22:18.077476Z",
     "shell.execute_reply.started": "2023-11-28T05:22:18.072975Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b21e969e-610c-430a-8bc8-f74ac02a2a49",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-28T05:22:18.222064Z",
     "iopub.status.busy": "2023-11-28T05:22:18.220969Z",
     "iopub.status.idle": "2023-11-28T05:22:18.549057Z",
     "shell.execute_reply": "2023-11-28T05:22:18.547663Z",
     "shell.execute_reply.started": "2023-11-28T05:22:18.222014Z"
    }
   },
   "outputs": [],
   "source": [
    "root_data = '../data/service_query/query.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "a2d79504-da82-4837-87e8-1fc152e243c1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-28T08:12:54.392464Z",
     "iopub.status.busy": "2023-11-28T08:12:54.391740Z",
     "iopub.status.idle": "2023-11-28T08:12:54.398709Z",
     "shell.execute_reply": "2023-11-28T08:12:54.397613Z",
     "shell.execute_reply.started": "2023-11-28T08:12:54.392414Z"
    }
   },
   "outputs": [],
   "source": [
    "def parse(input):\n",
    "    res = re.search(r'^(.*)(?=\\([^()]*\\)$)', input)\n",
    "    if res is None:\n",
    "        return ''\n",
    "    return res.group(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "102a2981-6352-4610-81fa-e9f9d52533ae",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-28T08:15:36.700690Z",
     "iopub.status.busy": "2023-11-28T08:15:36.699930Z",
     "iopub.status.idle": "2023-11-28T08:15:36.831804Z",
     "shell.execute_reply": "2023-11-28T08:15:36.830707Z",
     "shell.execute_reply.started": "2023-11-28T08:15:36.700638Z"
    }
   },
   "outputs": [],
   "source": [
    "query_list = []\n",
    "with open(root_data, 'r') as f:\n",
    "    for line in f:\n",
    "        data = line.strip().split('|')\n",
    "        if (5 - len(data)) > 0:\n",
    "            for i in range(5- len(data)):\n",
    "                data.append('')\n",
    "\n",
    "        if len(data) <5:\n",
    "            print(data)\n",
    "            break\n",
    "\n",
    "        query_list.append({'query': data[0], 'query_cnt': data[1], 'p_rank1': parse(data[2]), 'p_rank2': parse(data[3]), 'p_rank3': parse(data[4])})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "dac6a7e9-1dde-4292-974e-122c257e373f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-28T08:15:38.267665Z",
     "iopub.status.busy": "2023-11-28T08:15:38.266907Z",
     "iopub.status.idle": "2023-11-28T08:15:38.285113Z",
     "shell.execute_reply": "2023-11-28T08:15:38.284167Z",
     "shell.execute_reply.started": "2023-11-28T08:15:38.267615Z"
    }
   },
   "outputs": [],
   "source": [
    "query_pd = pd.DataFrame(query_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d96ce616-7005-4787-8dfc-d71bd6af7feb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-28T05:22:19.291843Z",
     "iopub.status.busy": "2023-11-28T05:22:19.291608Z",
     "iopub.status.idle": "2023-11-28T05:22:19.560979Z",
     "shell.execute_reply": "2023-11-28T05:22:19.559875Z",
     "shell.execute_reply.started": "2023-11-28T05:22:19.291823Z"
    }
   },
   "outputs": [],
   "source": [
    "queries = list(query_pd['query'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67e72690-fc4d-4477-a6c6-cb966cb078bc",
   "metadata": {},
   "source": [
    "# LOAD MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5059ea57-5065-4bac-adc8-bc178e05730e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-09T09:57:23.527043Z",
     "iopub.status.busy": "2023-12-09T09:57:23.526330Z",
     "iopub.status.idle": "2023-12-09T09:57:26.176523Z",
     "shell.execute_reply": "2023-12-09T09:57:26.175693Z",
     "shell.execute_reply.started": "2023-12-09T09:57:23.526985Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import (\n",
    "    AdamW,\n",
    "    AutoModel,\n",
    "    get_linear_schedule_with_warmup,\n",
    "    AutoTokenizer,\n",
    "    AutoConfig\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e1e29fc2-31f9-4bcb-8200-24e6afc23860",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-09T09:57:35.435559Z",
     "iopub.status.busy": "2023-12-09T09:57:35.434721Z",
     "iopub.status.idle": "2023-12-09T09:57:36.018538Z",
     "shell.execute_reply": "2023-12-09T09:57:36.017533Z",
     "shell.execute_reply.started": "2023-12-09T09:57:35.435501Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from src.utils import set_seed\n",
    "from src.trainer import SimcseTrainer\n",
    "from src.dataset import DATASET_MAPPING_DICT\n",
    "from src.utils import PreprocessorFactory \n",
    "from src.utils import get_model_argparse\n",
    "from src.model import MODEL_MAPPING_DICT\n",
    "from src.model import CONFIG_MAPPING_DICT\n",
    "from src.logger import Experi_Logger\n",
    "from config.nli_config import nli_parser_model_args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7368d224-2d0c-4c78-b349-b93dac187077",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-09T09:57:36.612968Z",
     "iopub.status.busy": "2023-12-09T09:57:36.612169Z",
     "iopub.status.idle": "2023-12-09T09:57:36.622103Z",
     "shell.execute_reply": "2023-12-09T09:57:36.621128Z",
     "shell.execute_reply.started": "2023-12-09T09:57:36.612909Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "args = nli_parser_model_args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "719b14c8-ee96-4457-8287-54168666e211",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-09T09:57:37.714328Z",
     "iopub.status.busy": "2023-12-09T09:57:37.713553Z",
     "iopub.status.idle": "2023-12-09T09:57:37.749359Z",
     "shell.execute_reply": "2023-12-09T09:57:37.748446Z",
     "shell.execute_reply.started": "2023-12-09T09:57:37.714257Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "args.device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "args.pretrained_model = '/home/x1112436/result/faq/modelfile/home/x1112436/model_file/sent_roberta'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "97599861-8f4b-476b-b6ef-fcc6ce6b4e62",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-09T09:57:38.270354Z",
     "iopub.status.busy": "2023-12-09T09:57:38.269547Z",
     "iopub.status.idle": "2023-12-09T09:57:43.239345Z",
     "shell.execute_reply": "2023-12-09T09:57:43.238119Z",
     "shell.execute_reply.started": "2023-12-09T09:57:38.270276Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = MODEL_MAPPING_DICT['sent_roberta'].from_pretrained(\n",
    "    args.pretrained_model, **vars(args), \n",
    ")\n",
    "tokenizer = AutoTokenizer.from_pretrained(args.pretrained_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dbbf6c2-2937-4f8d-b192-f93c54ef8a22",
   "metadata": {},
   "source": [
    "# load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "273715cb-1bc0-479d-b1c7-aca8dc51f8d6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-09T09:58:47.440245Z",
     "iopub.status.busy": "2023-12-09T09:58:47.439360Z",
     "iopub.status.idle": "2023-12-09T09:58:48.051208Z",
     "shell.execute_reply": "2023-12-09T09:58:48.049674Z",
     "shell.execute_reply.started": "2023-12-09T09:58:47.440147Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from skt.gcp import load_bigquery_ipython_magic, \\\n",
    "                    bq_to_pandas, \\\n",
    "                    get_bigquery_client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d9f76236-7577-444f-a73a-279957784e35",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-09T09:58:48.054919Z",
     "iopub.status.busy": "2023-12-09T09:58:48.053960Z",
     "iopub.status.idle": "2023-12-09T09:58:48.061999Z",
     "shell.execute_reply": "2023-12-09T09:58:48.060721Z",
     "shell.execute_reply.started": "2023-12-09T09:58:48.054855Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset = 'x1112436'\n",
    "log_table = 'faq_table'\n",
    "query = f\"\"\"\n",
    "\n",
    "SELECT  query,\n",
    "        answer,\n",
    "        intent_nm,\n",
    "        answer,\n",
    "        domain,\n",
    "        status\n",
    "FROM `skt-datahub.{dataset}.{log_table}`\n",
    "WHERE intent_nm !='' and intent_nm is not null\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eec467df-8601-4f4d-9d50-07d9733012fe",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-09T09:58:48.064111Z",
     "iopub.status.busy": "2023-12-09T09:58:48.063614Z",
     "iopub.status.idle": "2023-12-09T09:58:52.445917Z",
     "shell.execute_reply": "2023-12-09T09:58:52.444641Z",
     "shell.execute_reply.started": "2023-12-09T09:58:48.064084Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: exception on print statistics\n",
      "unsupported operand type(s) for /: 'NoneType' and 'int'\n",
      "Downloading: 100%|\u001b[32m██████████\u001b[0m|\n"
     ]
    }
   ],
   "source": [
    "faq_table = bq_to_pandas(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3cbb1d6e-5d02-4405-901b-a2d5f46c49d1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-09T09:59:12.094180Z",
     "iopub.status.busy": "2023-12-09T09:59:12.093182Z",
     "iopub.status.idle": "2023-12-09T09:59:12.118388Z",
     "shell.execute_reply": "2023-12-09T09:59:12.117399Z",
     "shell.execute_reply.started": "2023-12-09T09:59:12.094116Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "idx2intent_nm = list(faq_table.intent_nm.unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2a7cdcc-2163-48b7-89ad-8855a65d2c7b",
   "metadata": {},
   "source": [
    "# Inference Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "709174f3-4c88-41e8-b65b-8cb06ed2aab8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-09T09:59:45.636345Z",
     "iopub.status.busy": "2023-12-09T09:59:45.635516Z",
     "iopub.status.idle": "2023-12-09T09:59:45.642598Z",
     "shell.execute_reply": "2023-12-09T09:59:45.641167Z",
     "shell.execute_reply.started": "2023-12-09T09:59:45.636272Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import (\n",
    "    DataLoader, Dataset\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "12211454-1da5-481f-a09c-6bde4de27e02",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-09T09:59:45.759766Z",
     "iopub.status.busy": "2023-12-09T09:59:45.759064Z",
     "iopub.status.idle": "2023-12-09T09:59:45.765656Z",
     "shell.execute_reply": "2023-12-09T09:59:45.764417Z",
     "shell.execute_reply.started": "2023-12-09T09:59:45.759709Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from typing import List, Any, Union, Dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "da2313ef-2551-4d23-9015-2dce369a6f78",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-09T09:59:52.544337Z",
     "iopub.status.busy": "2023-12-09T09:59:52.543551Z",
     "iopub.status.idle": "2023-12-09T09:59:52.551602Z",
     "shell.execute_reply": "2023-12-09T09:59:52.550411Z",
     "shell.execute_reply.started": "2023-12-09T09:59:52.544259Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class SingleSentenceInput:\n",
    "    sentence_a: str = None\n",
    "    a_input_ids: List[int] = None\n",
    "    a_attention_mask: List[int] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4415b8bb-2203-4427-8361-48a727005ce3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-09T09:59:58.223890Z",
     "iopub.status.busy": "2023-12-09T09:59:58.222908Z",
     "iopub.status.idle": "2023-12-09T09:59:58.245607Z",
     "shell.execute_reply": "2023-12-09T09:59:58.244882Z",
     "shell.execute_reply.started": "2023-12-09T09:59:58.223831Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class EmbeddingDataset(Dataset):\n",
    "    def __init__(\n",
    "            self,\n",
    "            args,\n",
    "            features:List[SingleSentenceInput],\n",
    "            max_length,\n",
    "            tokenizer,\n",
    "            **kwargs\n",
    "    ):\n",
    "        super(EmbeddingDataset, self).__init__()\n",
    "        self.args = args\n",
    "        self.features = features\n",
    "        self.max_length = max_length\n",
    "        self.pad_token_id = tokenizer.pad_token_id\n",
    "        self.sep_token_id = tokenizer.sep_token_id if tokenizer.sep_token_id else tokenizer.eos_token_id\n",
    "\n",
    "    def __getitem__(self, index) -> Dict[str, Any]:\n",
    "        feature = self.features[index]\n",
    "        return {\n",
    "            'a_sentence': feature.sentence_a,\n",
    "            'a_input_ids': torch.tensor(feature.a_input_ids, dtype=torch.long),\n",
    "            'a_attention_mask': torch.tensor(feature.a_attention_mask, dtype=torch.long)\n",
    "        }\n",
    "    def __len__(self):\n",
    "        return len(self.features)\n",
    "    \n",
    "    def loader(self, shuffle:bool=True, batch_size:int=64):\n",
    "        return DataLoader(self, shuffle=shuffle, batch_size=batch_size, collate_fn=self.collater)\n",
    "\n",
    "    def collater(self, batch: List[Dict[str, Any]]) -> Dict[str, Any]:\n",
    "\n",
    "        a_sentence = [data['a_sentence'] for data in batch]\n",
    "        a_input_ids = [data['a_input_ids'] for data in batch]\n",
    "        a_attention_mask = [data['a_attention_mask'] for data in batch]\n",
    "        ##  token level encoding\n",
    "        batch_size = len(batch)\n",
    "        sizes = [len(s) for s in a_input_ids]\n",
    "        target_size = min(max(sizes), self.max_length)\n",
    "        \"\"\" torch.full -> creates a tensor of a given shape and fills it with a scalar value self.pad_token_id here\"\"\"\n",
    "        a_collated_ids = torch.full((batch_size, target_size), self.pad_token_id, dtype=torch.long)\n",
    "        a_collated_attention_masks = torch.zeros((batch_size, target_size), dtype=torch.long)\n",
    "\n",
    "        \"\"\" cut data if size > target_size else: fill by self.pad_token_id \"\"\"\n",
    "        for i, (input_id, attention_m, size) in enumerate(\n",
    "                zip(a_input_ids, a_attention_mask, sizes)):\n",
    "            diff = target_size - size\n",
    "            if diff < 0:\n",
    "                a_collated_ids[i, :target_size] = input_id[:target_size]\n",
    "                a_collated_ids[i, -1] = self.sep_token_id\n",
    "                a_collated_attention_masks[i, :target_size] = attention_m[:target_size]\n",
    "\n",
    "            else:\n",
    "                a_collated_ids[i, :size] = input_id\n",
    "                a_collated_attention_masks[i, :size] = attention_m\n",
    "\n",
    "        return {\n",
    "            'a_sentence': a_sentence,\n",
    "            'a_input_ids': a_collated_ids,\n",
    "            'a_attention_mask': a_collated_attention_masks\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e556f741-9d9f-42f5-a8a3-13839dab3aa9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-09T10:00:03.681790Z",
     "iopub.status.busy": "2023-12-09T10:00:03.681003Z",
     "iopub.status.idle": "2023-12-09T10:00:03.692782Z",
     "shell.execute_reply": "2023-12-09T10:00:03.691506Z",
     "shell.execute_reply.started": "2023-12-09T10:00:03.681734Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from src.utils.abs_preprocess import AbsPreprocessor\n",
    "\n",
    "class Testprocessor(AbsPreprocessor):\n",
    "\n",
    "    @classmethod\n",
    "    def preprocess(cls, tokenizer,  input_list:List) -> None:\n",
    "        \"\"\" try read tsv file using pandas first if [memory or parse] error catched use other reading method  \"\"\"\n",
    "    \n",
    "        feature_list = list()\n",
    "        skipped_line = 0\n",
    "\n",
    "        for i, line in enumerate(input_list):\n",
    "            try:\n",
    "                a_encoded_sentence = cls.tokenizing(input=line, tokenizer=tokenizer, tokenizer_input=None)\n",
    "                feature_list.append(\n",
    "                    SingleSentenceInput(\n",
    "                        sentence_a = line,\n",
    "                        a_input_ids = a_encoded_sentence.input_ids,\n",
    "                        a_attention_mask=a_encoded_sentence.attention_mask,\n",
    "                    )\n",
    "                )\n",
    "            except Exception as e:\n",
    "                print(f'Error occurs in {i} lines in preprocessing')\n",
    "                print(line)\n",
    "                print(e)\n",
    "                break\n",
    "\n",
    "        return feature_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a28d48f6-7589-4f64-97e7-33a69884dc97",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-09T10:00:30.867143Z",
     "iopub.status.busy": "2023-12-09T10:00:30.866375Z",
     "iopub.status.idle": "2023-12-09T10:00:30.880209Z",
     "shell.execute_reply": "2023-12-09T10:00:30.879337Z",
     "shell.execute_reply.started": "2023-12-09T10:00:30.867086Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def encode(chunk_list):\n",
    "    emedding_dict = dict()\n",
    "    embedding_list = []\n",
    "    query_list = []\n",
    "    for chunk in chunk_list:\n",
    "        chunk_process = Testprocessor.preprocess(tokenizer = tokenizer, input_list = chunk)\n",
    "        chunk_dataset = EmbeddingDataset(args=args, features=chunk_process, max_length=args.model_max_len, tokenizer=tokenizer)\n",
    "        chunk_dataloader = chunk_dataset.loader(shuffle=False, batch_size=400)\n",
    "        model.eval()\n",
    "        with torch.no_grad():   \n",
    "            for batch_idx, batch in enumerate(chunk_dataloader): \n",
    "                batch = {key: (item.to(args.device) if type(item) == torch.Tensor else item) for key, item in batch.items()}\n",
    "                a_embedding = model(batch['a_input_ids'], batch['a_attention_mask'])\n",
    "                a_sentence = batch['a_sentence']\n",
    "                query_list.extend(a_sentence)\n",
    "                embedding_list.append(a_embedding)\n",
    "            \n",
    "    embeddings = torch.cat(embedding_list, 0) \n",
    "    return embeddings, query_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "badc0501-ee25-4441-b93e-e8eea853688a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddf94671-ac3e-4f5c-b843-b29a089c84be",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a573c65-bae7-4640-8547-941a8b48ada1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "service_query_list = []\n",
    "embedding_service_query = []\n",
    "with torch.no_grad():   \n",
    "    for batch_idx, batch in enumerate(tqdm(service_query_dataloader)): \n",
    "        batch = {key: (item.to(args.device) if type(item) == torch.Tensor else item) for key, item in batch.items()}\n",
    "        a_embedding = model(batch['a_input_ids'], batch['a_attention_mask'])\n",
    "        a_sentence = batch['a_sentence']\n",
    "        service_query_list.extend(a_sentence)\n",
    "        embedding_service_query.append(a_embedding)\n",
    "    embedding_service_query = torch.cat(embedding_service_query, 0) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecf15024-8c54-4f34-a03d-3dee1dac5490",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "intent_list = []\n",
    "embedding_intent = []\n",
    "with torch.no_grad():   \n",
    "    for batch_idx, batch in enumerate(tqdm(intent_dataloader)): \n",
    "        batch = {key: (item.to(args.device) if type(item) == torch.Tensor else item) for key, item in batch.items()}\n",
    "        a_embedding = model(batch['a_input_ids'], batch['a_attention_mask'])\n",
    "        a_sentence = batch['a_sentence']\n",
    "        intent_list.extend(a_sentence)\n",
    "        embedding_intent.append(a_embedding)\n",
    "    embedding_intent = torch.cat(embedding_intent, 0) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04b77b7c-e4fa-409f-88c1-54a0eaa97670",
   "metadata": {},
   "source": [
    "# TOP K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3095dff1-5c72-4128-99a9-22813f00ab51",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "values, indices = torch.topk(F.normalize(embedding_service_query, dim =1) @ F.normalize(embedding_intent, dim=1).T, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f61d235-f740-406f-85e4-0a5b487c974f",
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85e49974-dfb4-4dd6-9174-221970d70d63",
   "metadata": {},
   "outputs": [],
   "source": [
    "values[values < threshold] = -1\n",
    "indices[values < threshold] = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf2cbc17-dbb9-412f-8a4b-66a4ee7d7ab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = indices.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dea03703-fae9-4f28-8385-1b9f7c9547ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_dict = dict()\n",
    "for i in range(embedding_service_query.size()[0]):        \n",
    "    predict_dict[service_queries[i]] = [(intent_list[indices[i, j]], round(values[i,j].cpu().item(), 3)) for j in range(3) if indices[i,j] != -1]\n",
    "\n",
    "predict_list = []\n",
    "for key, value in predict_dict.items():\n",
    "    query = key\n",
    "    for i in range(3 - len(value)):\n",
    "        value.append('')\n",
    "        \n",
    "    predict_list.append({'query': query, 'n_rank1': value[0], 'n_rank2': value[1], 'n_rank3': value[2]})\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "921ee472-aaa8-4462-803f-7e804a68604d",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_pd = pd.DataFrame(predict_list)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
